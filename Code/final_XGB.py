import numpy as npimport pandas as pdimport matplotlib.pyplot as pltfrom sklearn.metrics import r2_scorefrom scipy.stats import chi2_contingency, f_onewayfrom statsmodels.stats.outliers_influence import variance_inflation_factorfrom sklearn.model_selection import train_test_splitfrom sklearn.ensemble import RandomForestClassifierfrom sklearn.metrics import accuracy_score, classification_report, precision_recall_fscore_supportimport warningsimport osimport time print('Program is running')print()start_time = time.time()df1 = pd.read_excel('../Data/case_study1.xlsx')df2 = pd.read_excel('../Data/case_study2.xlsx')df1 = df1[df1['Age_Newest_TL'] != -99999]def count_of_null(df2, null_value):        filtered_df = df2.eq(null_value)    return filtered_df    null_count_df2 = count_of_null(df2, -99999).sum().reset_index()null_count_df2.rename(columns={0: 'count'}, inplace=True)null_count_df2[null_count_df2['count'] != 0].sort_values(by = 'count', ascending = False)columns_to_be_removed = null_count_df2[null_count_df2['count'] > 10000]['index'].tolist()df2 = df2[['PROSPECTID', 'time_since_recent_payment',       'num_times_delinquent',       'max_recent_level_of_deliq', 'num_deliq_6mts', 'num_deliq_12mts',       'num_deliq_6_12mts',       'num_times_30p_dpd', 'num_times_60p_dpd', 'num_std', 'num_std_6mts',       'num_std_12mts', 'num_sub', 'num_sub_6mts', 'num_sub_12mts', 'num_dbt',       'num_dbt_6mts', 'num_dbt_12mts', 'num_lss', 'num_lss_6mts',       'num_lss_12mts', 'recent_level_of_deliq', 'tot_enq', 'CC_enq',       'CC_enq_L6m', 'CC_enq_L12m', 'PL_enq', 'PL_enq_L6m', 'PL_enq_L12m',       'time_since_recent_enq', 'enq_L12m', 'enq_L6m', 'enq_L3m',       'MARITALSTATUS', 'EDUCATION', 'AGE', 'GENDER', 'NETMONTHLYINCOME',       'Time_With_Curr_Empr', 'pct_of_active_TLs_ever',       'pct_opened_TLs_L6m_of_L12m', 'pct_currentBal_all_TL',       'CC_Flag', 'PL_Flag', 'pct_PL_enq_L6m_of_L12m',       'pct_CC_enq_L6m_of_L12m', 'pct_PL_enq_L6m_of_ever',       'pct_CC_enq_L6m_of_ever','HL_Flag',       'GL_Flag', 'last_prod_enq2', 'first_prod_enq2', 'Credit_Score',       'Approved_Flag']]for i in df2.columns:    df2 = df2[df2[i] != -99999]df = pd.merge(df1, df2, how = 'inner', right_on='PROSPECTID', left_on = 'PROSPECTID')cat_var = []for i in df.columns:    if df[i].dtype == 'object' and i != 'Approved_Flag':        cat_var.append(i)cat_var# Chi-Square Testp_val = []for i in cat_var:    chi2, pval, _, _, = chi2_contingency(pd.crosstab(df[i], df['Approved_Flag']))    print(i, ':', pval)    p_val.append(pval)        num_var = []for i in df.columns:    if df[i].dtype != 'object' and i not in ['PROSPECTID', 'Approved_Flag']:        num_var.append(i)num_var# VIF sequentially checkvif_data = df[num_var]total_columns = vif_data.shape[1]columns_to_be_kept = []column_index = 0for i in range (0,total_columns):        vif_value = variance_inflation_factor(vif_data, column_index)    print (column_index,'---',vif_value)            if vif_value <= 6:        columns_to_be_kept.append( num_var[i] )        column_index = column_index+1        else:        vif_data = vif_data.drop([ num_var[i] ] , axis=1)columns_to_be_kept_num = []for i in columns_to_be_kept:    a = list(df[i])    b = list(df['Approved_Flag'])        group_p1 = [value for value, group in zip(a, b) if group == 'P1']    group_p2 = [value for value, group in zip(a, b) if group == 'P2']    group_p3 = [value for value, group in zip(a, b) if group == 'P3']    group_p4 = [value for value, group in zip(a, b) if group == 'P4']        f_stats, p_value = f_oneway(group_p1, group_p2, group_p3, group_p4)        if p_value <= 0.05:        columns_to_be_kept_num.append(i)        final_features = columns_to_be_kept_num + cat_vardf = df[final_features + ['Approved_Flag']]mapping = {'SSC': 1, '12TH': 2, 'GRADUATE': 3, 'UNDER GRADUATE': 3, 'POST-GRADUATE': 4, 'OTHERS': 1, 'PROFESSIONAL': 3}df['EDUCATION'] = df['EDUCATION'].replace(mapping).astype('int')# One hot encoding for other categorical variablesdf_encoded = pd.get_dummies(df, columns=['MARITALSTATUS', 'GENDER' , 'last_prod_enq2' ,'first_prod_enq2'], dtype=int)# XGBOOSTimport xgboost as xgbfrom sklearn.preprocessing import LabelEncoderxgb_classifier = xgb.XGBClassifier(objective='multi:softmax',  num_class=4)y = df_encoded['Approved_Flag']x = df_encoded. drop ( ['Approved_Flag'], axis = 1 )label_encoder = LabelEncoder()y_encoded = label_encoder.fit_transform(y)x_train, x_test, y_train, y_test = train_test_split(x, y_encoded, test_size=0.2, random_state=42)xgb_classifier.fit(x_train, y_train)y_pred = xgb_classifier.predict(x_test)accuracy = accuracy_score(y_test, y_pred)print(f'\nAccuracy: {accuracy:.2f}\n')precision, recall, f1_score, _ = precision_recall_fscore_support(y_test, y_pred)for i, v in enumerate(['p1', 'p2', 'p3', 'p4']):    print(f"Class {v}:")    print(f"Precision: {precision[i]}")    print(f"Recall: {recall[i]}")    print(f"F1 Score: {f1_score[i]}\n")df3 = pd.read_excel('../Data/Unseen_Dataset.xlsx')cols_in_df = list(df.columns)cols_in_df.pop(42)df_unseen = df3[cols_in_df]mapping = {'SSC': 1, '12TH': 2, 'GRADUATE': 3, 'UNDER GRADUATE': 3, 'POST-GRADUATE': 4, 'OTHERS': 1, 'PROFESSIONAL': 3}df_unseen['EDUCATION'] = df_unseen['EDUCATION'].replace(mapping).astype('int')# One hot encoding for other categorical variablesdf_unseen_encoded = pd.get_dummies(df_unseen, columns=['MARITALSTATUS', 'GENDER' , 'last_prod_enq2' ,'first_prod_enq2'], dtype=int)model = xgb.XGBClassifier(objective='multi:softmax', learning_rate= 0.2, max_depth= 3, n_estimators= 200, alpha = 10)model.fit(x_train, y_train)y_pred_unseen = model.predict(df_unseen_encoded)df3['Target'] = y_pred_unseendf3.to_html('../data/final_prediction.html')df3.to_csv('../data/final_prediction.csv')end_time = time.time()elapsed_time = end_time - start_timeprint('Total run time of the program- ' + str (round(elapsed_time, 2)) + 'sec')input("Press enter to exit.")